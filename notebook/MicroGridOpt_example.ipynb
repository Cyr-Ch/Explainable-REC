{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a461c72d",
      "metadata": {
        "id": "a461c72d"
      },
      "source": [
        "# MicroGrid\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b7f90c8",
      "metadata": {
        "id": "8b7f90c8"
      },
      "source": [
        "## MicroGrid System Overview\n",
        "\n",
        "\n",
        "\n",
        "![](new_design.png)\n",
        "\n",
        "Advantages of this multi-agent design with autogen:\n",
        "- Collaborative Problem Solving: The collaboration among the user proxy agent and the assistant agents fosters a cooperative problem-solving environment. The agents can share information and knowledge, allowing them to complement each other's abilities and collectively arrive at better solutions. On the other hand, the Safeguard acts as a virtual adversarial checker, which can perform another safety check pass on the generated code.\n",
        "\n",
        "- Modularity: The division of tasks into separate agents promotes modularity in the system. Each agent can be developed, tested, and maintained independently, simplifying the overall development process and facilitating code management.\n",
        "\n",
        "- Memory Management: The UnbiasedCathode agent's role in maintaining memory related to user interactions is crucial. The memory retention allows the agents to have context about a user's prior questions, making the decision-making process more informed and context-aware.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "717de2e0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: optiguide in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (0.0.1)\n",
            "Requirement already satisfied: termcolor in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from optiguide) (2.3.0)\n",
            "Requirement already satisfied: eventlet in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from optiguide) (0.33.3)\n",
            "Requirement already satisfied: flaml in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from optiguide) (2.1.1)\n",
            "Requirement already satisfied: gurobipy in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from optiguide) (10.0.3)\n",
            "Requirement already satisfied: openai in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from optiguide) (0.28.1)\n",
            "Requirement already satisfied: diskcache in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from optiguide) (5.6.3)\n",
            "Requirement already satisfied: autogen in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from optiguide) (1.0.16)\n",
            "Requirement already satisfied: PyYAML in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from autogen->optiguide) (6.0.1)\n",
            "Requirement already satisfied: twine in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from autogen->optiguide) (4.0.2)\n",
            "Requirement already satisfied: autopep8 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from autogen->optiguide) (2.0.4)\n",
            "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from autogen->optiguide) (58.0.4)\n",
            "Requirement already satisfied: docopt in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from autogen->optiguide) (0.6.2)\n",
            "Requirement already satisfied: pycodestyle>=2.10.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from autopep8->autogen->optiguide) (2.11.1)\n",
            "Requirement already satisfied: tomli in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from autopep8->autogen->optiguide) (2.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from eventlet->optiguide) (1.15.0)\n",
            "Requirement already satisfied: dnspython>=1.15.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from eventlet->optiguide) (2.4.2)\n",
            "Requirement already satisfied: greenlet>=0.3 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from eventlet->optiguide) (3.0.1)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from flaml->optiguide) (1.26.2)\n",
            "Requirement already satisfied: aiohttp in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from openai->optiguide) (3.9.3)\n",
            "Requirement already satisfied: tqdm in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from openai->optiguide) (4.66.1)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from openai->optiguide) (2.31.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai->optiguide) (2023.11.17)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai->optiguide) (2.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai->optiguide) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai->optiguide) (3.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->optiguide) (1.9.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->optiguide) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->optiguide) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->optiguide) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->optiguide) (1.4.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai->optiguide) (4.0.3)\n",
            "Requirement already satisfied: readme-renderer>=35.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from twine->autogen->optiguide) (42.0)\n",
            "Requirement already satisfied: requests-toolbelt!=0.9.0,>=0.8.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from twine->autogen->optiguide) (1.0.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from twine->autogen->optiguide) (13.7.0)\n",
            "Requirement already satisfied: pkginfo>=1.8.1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from twine->autogen->optiguide) (1.9.6)\n",
            "Requirement already satisfied: keyring>=15.1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from twine->autogen->optiguide) (24.3.0)\n",
            "Requirement already satisfied: rfc3986>=1.4.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from twine->autogen->optiguide) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from twine->autogen->optiguide) (6.8.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=3.6->twine->autogen->optiguide) (3.17.0)\n",
            "Requirement already satisfied: jaraco.classes in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from keyring>=15.1->twine->autogen->optiguide) (3.3.0)\n",
            "Requirement already satisfied: docutils>=0.13.1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from readme-renderer>=35.0->twine->autogen->optiguide) (0.20.1)\n",
            "Requirement already satisfied: nh3>=0.2.14 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from readme-renderer>=35.0->twine->autogen->optiguide) (0.2.14)\n",
            "Requirement already satisfied: Pygments>=2.5.1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from readme-renderer>=35.0->twine->autogen->optiguide) (2.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from rich>=12.0.0->twine->autogen->optiguide) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine->autogen->optiguide) (0.1.2)\n",
            "Requirement already satisfied: more-itertools in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from jaraco.classes->keyring>=15.1->twine->autogen->optiguide) (10.1.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: rsome in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (1.2.6)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from rsome) (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from rsome) (1.26.2)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from rsome) (1.11.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from pandas>=0.25.0->rsome) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from pandas>=0.25.0->rsome) (2023.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/cchaabani/Library/Python/3.9/lib/python/site-packages (from pandas>=0.25.0->rsome) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.0->rsome) (1.15.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Using pip 21.2.4 from /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages/pip (python 3.9)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting openai==0.28.1\n",
            "  Using cached openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "Collecting requests>=2.20\n",
            "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Collecting aiohttp\n",
            "  Using cached aiohttp-3.9.3-cp39-cp39-macosx_11_0_arm64.whl (388 kB)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Using cached charset_normalizer-3.3.2-cp39-cp39-macosx_11_0_arm64.whl (120 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Using cached urllib3-2.2.0-py3-none-any.whl (120 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Using cached yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl (81 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Using cached frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (53 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Using cached multidict-6.0.4-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
            "Installing collected packages: multidict, idna, frozenlist, yarl, urllib3, charset-normalizer, certifi, attrs, async-timeout, aiosignal, tqdm, requests, aiohttp, openai\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.0.4\n",
            "    Uninstalling multidict-6.0.4:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/multidict/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/multidict-6.0.4.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/multidict/\n",
            "      Successfully uninstalled multidict-6.0.4\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/idna/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/idna-3.6.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/idna/\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.4.1\n",
            "    Uninstalling frozenlist-1.4.1:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/frozenlist/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/frozenlist-1.4.1.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/frozenlist/\n",
            "      Successfully uninstalled frozenlist-1.4.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.9.4\n",
            "    Uninstalling yarl-1.9.4:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/yarl/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/yarl-1.9.4.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/yarl/\n",
            "      Successfully uninstalled yarl-1.9.4\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.0\n",
            "    Uninstalling urllib3-2.2.0:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/urllib3/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/urllib3-2.2.0.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/urllib3/\n",
            "      Successfully uninstalled urllib3-2.2.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/charset_normalizer/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/bin/normalizer\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/charset_normalizer-3.3.2.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/charset_normalizer/\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  changing mode of /Users/cchaabani/Library/Python/3.9/bin/normalizer to 755\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/certifi/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/certifi-2023.11.17.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/certifi/\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.2.0\n",
            "    Uninstalling attrs-23.2.0:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/attr/\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/attrs/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/attr/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/attrs-23.2.0.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/attrs/\n",
            "      Successfully uninstalled attrs-23.2.0\n",
            "  Attempting uninstall: async-timeout\n",
            "    Found existing installation: async-timeout 4.0.3\n",
            "    Uninstalling async-timeout-4.0.3:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/async_timeout/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/async_timeout-4.0.3.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/async_timeout/\n",
            "      Successfully uninstalled async-timeout-4.0.3\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.3.1\n",
            "    Uninstalling aiosignal-1.3.1:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/aiosignal/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/aiosignal-1.3.1.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/aiosignal/\n",
            "      Successfully uninstalled aiosignal-1.3.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/tqdm/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/bin/tqdm\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/tqdm-4.66.1.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/tqdm/\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  changing mode of /Users/cchaabani/Library/Python/3.9/bin/tqdm to 755\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/requests/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/requests-2.31.0.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/requests/\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.9.3\n",
            "    Uninstalling aiohttp-3.9.3:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/aiohttp/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/aiohttp-3.9.3.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/aiohttp/\n",
            "      Successfully uninstalled aiohttp-3.9.3\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.28.1\n",
            "    Uninstalling openai-0.28.1:\n",
            "      Removing file or directory /Users/cchaabani/Library/Caches/com.apple.python/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/bin/openai\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai-0.28.1.dist-info/\n",
            "      Removing file or directory /Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/\n",
            "      Successfully uninstalled openai-0.28.1\n",
            "  changing mode of /Users/cchaabani/Library/Python/3.9/bin/openai to 755\n",
            "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 certifi-2023.11.17 charset-normalizer-3.3.2 frozenlist-1.4.1 idna-3.6 multidict-6.0.4 openai-0.28.1 requests-2.31.0 tqdm-4.66.1 urllib3-2.2.0 yarl-1.9.4\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install Required Packages\n",
        "%pip install optiguide\n",
        "%pip install rsome\n",
        "%pip install --force-reinstall -v \"openai==0.28.1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9a3b79c4",
      "metadata": {
        "id": "9a3b79c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# test Gurobi installation\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "from eventlet.timeout import Timeout\n",
        "\n",
        "# import auxillary packages\n",
        "import requests  # for loading the example source code\n",
        "import openai\n",
        "\n",
        "# import flaml and autogen\n",
        "from flaml import autogen\n",
        "from flaml.autogen.agentchat import Agent, UserProxyAgent\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aedf19e7",
      "metadata": {
        "id": "aedf19e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'api_key_gpt4': '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', 'api_key_gpt3': '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'}\n"
          ]
        }
      ],
      "source": [
        "with open(\"api_keys.json\", \"r\") as keyfile:\n",
        "    api_key = json.load(keyfile)\n",
        "\n",
        "print(api_key)\n",
        "autogen.oai.ChatCompletion.start_logging()\n",
        "config_list = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        "    filter_dict={\n",
        "        \"model\": {\n",
        "            'gpt-4'\n",
        "        }\n",
        "    }\n",
        ")\n",
        "#3.5-turbo-1106',\n",
        "config_list = [\n",
        "    {\n",
        "        'model': 'gpt-3.5-turbo-1106',\n",
        "        'api_key': api_key['api_key_gpt3']\n",
        "    }]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9e7e728",
      "metadata": {
        "id": "e9e7e728"
      },
      "source": [
        "Now, let's import the source code (loading from URL) and also some training examples (defined as string blow)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ca962ac5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca962ac5",
        "outputId": "4a789991-8ba1-46f3-aad5-7fbaaaff7f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import gurobipy as gp\n",
            "from gurobipy import GRB\n",
            "import numpy as np\n",
            "\n",
            "# Define all parameters\n",
            "m = 3  # 5 timesteps\n",
            "n = 4  # 6 prosumers\n",
            "Pprod = np.array([[65, 45, 36, 25],\n",
            "                  [60, 40, 30, 27],\n",
            "                  [69, 44, 31, 26]])\n",
            ".\n",
            ".\n",
            ".\n",
            "\n",
            "print(\"Import:\", Pimport)\n",
            "print(\"Export:\", Pexport)\n",
            "print(\"Charge Battery:\", Bcharge)\n",
            "print(\"Discharge Battery:\", Bdischarge)\n",
            "print(\"SoE:\", Soe)\n",
            "print(\"SoEnext:\", soenext)\n",
            "'''\n",
            "\n",
            "m = model\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the source code of materials example\n",
        "code_url = \"../benchmark/application/microgrid_gurobi.py\"\n",
        "code = open(code_url, \"r\").read() # for local files\n",
        "\n",
        "# DEBUG\n",
        "# show the first head and tail of the source code\n",
        "print(\"\\n\".join(code.split(\"\\n\")[:10]))\n",
        "print(\".\\n\" * 3)\n",
        "print(\"\\n\".join(code.split(\"\\n\")[-10:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e31c4b36",
      "metadata": {
        "code_folding": [],
        "id": "e31c4b36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At the timestep 2 if the community's load doubles, what would be the profit?\n",
            "python for load in range(Pcons[1]):\tPcons[1][load] = 2*Pcons[1][load]\n",
            "If the community's load triples, how much I get profit?\n",
            "python Pcons = Pcons*3\n",
            "What should be the state of energy of the battery if the community's load consumption is reduced to half?\n",
            "python Pcons = Pcons/2\n",
            "What would be the profit if the community exports are smaller than this amount of power [10,30,20] to the grid?\n",
            "python model.addConstr(Pexp<=np.array([10,30,20]))\n",
            "What would be the profit if the community imports are smaller than this amount of power [10,30,20] from the grid?\n",
            "python model.addConstr(Pimp<=np.array([10,30,20]))\n",
            "What would be the profit if the community imports increase by 18%?\n",
            "model.addConstrs(Pimp[t] == Pimp[t]*(100+18)/100 for t in range(len(Pimp)))\n",
            "What would be the profit if the community imports decrease by 40%?\n",
            "model.addConstrs(Pimp[t] == Pimp[t]*(100-40)/100 for t in range(len(Pimp)))\n",
            "What would be the profit if the community imports decrease by 72% at the time step 2?\n",
            "model.addConstr(Pimp[1] == Pimp[1]*(100-72)/100)\n",
            "What would be the profit if the community exports decrease by 78%?\n",
            "model.addConstrs(Pexp[t] == Pexp[t]*(100-78)/100 for t in range(len(Pimp)))\n",
            "What would be the profit if the community exports decrease by 78% at the time step 2?\n",
            "model.addConstr(Pexp[1] == Pexp[1]*(100-78)/100)\n",
            "What would be the profit if the community exports increase by 12%?\n",
            "model.addConstrs(Pexp[t] == Pexp[t]*(100+12)/100 for t in range(len(Pimp)))\n",
            "What is the current energy production for participant 2?\n",
            "print(Pprod[len(Pprod)-1][1])\n",
            "What is the current energy production for participant 3?\n",
            "print(Pprod[len(Pprod)-1][2])\",-26.111111111111114,\"\n",
            "What is the energy production for participant 1 at time step 2?\"\n",
            "What is the energy production for participant 2 at time step 3?\n",
            "print(Pprod[2][1])\n",
            "What is the energy production for participant 3 at time step 1?\n",
            "print(Pprod[0][2])\n",
            "What would be the profit if the production decreases by 65%?\n",
            "Pprod = Pprod*(100-65)/100\n",
            "What would be the profit if the production decreases by 32%?\n",
            "Pprod = Pprod*(100-32)/100\n",
            "What would be the profit if the production decreases by 23%?\n",
            "Pprod = Pprod*(100-23)/100\n",
            "What would be the profit if the production increases by 63%?\n",
            "Pprod = Pprod*(100+63)/100\n",
            "What would be the profit if the production increases by 87%?\n",
            "Pprod = Pprod*(100+87)/100\n",
            "What would be the profit if the production increases by 69%?\n",
            "Pprod = Pprod*(100+69)/100\n",
            "What would be the profit if the production increases by 2%?\n",
            "Pprod = Pprod*(100+2)/100\n",
            "What is the current energy consumption for participant 3?\n",
            "print(Pcons[len(Pprod)-1][2])\n",
            "What is the current energy consumption for participant 4?\n",
            "print(Pcons[len(Pprod)-1][3])\n",
            "What is the energy consumption for participant 1 at time step 3?\n",
            "print(Pcons[2][0])\n",
            "What is the energy consumption for participant 2 at time step 1?\n",
            "print(Pcons[0][1])\n",
            "What is the energy consumption for participant 2 at time step 2?\n",
            "print(Pcons[1][1])\n",
            "What is the energy consumption for participant 3 at time step 2?\n",
            "print(Pcons[1][2])\n",
            "What is the energy consumption for participant 4 at time step 3?\n",
            "print(Pcons[2][3])\n",
            "What would be the profit if the consumption decreases by 24%?\n",
            "Pcons = Pcons*(100-24)/100\n",
            "What would be the profit if the consumption decreases by 62%?\n",
            "Pcons = Pcons*(100-62)/100\n",
            "What would be the profit if the consumption increases by 20%?\n",
            "Pcons = Pcons*(100+20)/100\n",
            "What would be the profit if the consumption increases by 44%?\n",
            "Pcons = Pcons*(100+44)/100\n",
            "What would be the profit if the consumption increases by 28%?\n",
            "Pcons = Pcons*(100+28)/100\n",
            "What would be the profit if the consumption increases by 12%?\n",
            "Pcons = Pcons*(100+12)/100\n",
            "What would be the profit if the consumption increases by 96%?\n",
            "Pcons = Pcons*(100+96)/100\n",
            "What is the current energy load for participant 3?\n",
            "print(Pcons[len(Pprod)-1][2])\n",
            "What is the energy load for participant 2 at time step 1?\n",
            "print(Pcons[0][1])\n",
            "What is the energy load for participant 3 at time step 2?\n",
            "print(Pcons[1][2])\n",
            "What is the energy load for participant 4 at time step 2?\n",
            "print(Pcons[1][3])\n",
            "What is the energy load for participant 4 at time step 3?\n",
            "print(Pcons[2][3])\n",
            "What would be the profit if the community load decreases by 66%?\n",
            "Pcons = Pcons*(100-66)/100\n",
            "What would be the profit if the community load decreases by 51%?\n",
            "Pcons = Pcons*(100-51)/100\n",
            "What would be the profit if the community load increases by 1%?\n",
            "Pcons = Pcons*(100+1)/100\n",
            "What would be the profit if the community load increases by 78%?\n",
            "Pcons = Pcons*(100+78)/100\n",
            "What would happen if prosumer 1 shifts 14% of their load at timestep 1 to timestep 1+1\n",
            "Pcons[0][0] = Pcons[0][0]*(100-14)/100 \\nPcons[0+1][0] = Pcons[0+1][0] + Pcons[0][0]* 14/100\n",
            "What would happen if prosumer 2 shifts 5% of their load at timestep 1 to timestep 1+1\n",
            "Pcons[0][1] = Pcons[0][1]*(100-5)/100 \\nPcons[0+1][1] = Pcons[0+1][1] + Pcons[0][1]* 5/100\n",
            "What would happen if prosumer 4 changes 90% of their load at timestep 2 to timestep 2+1\n",
            "Pcons[1][3] = Pcons[1][3]*(100-90)/100 \\nPcons[1+1][3] =Pcons[1+1][3] + Pcons[1][3]*90/100\n",
            "What would happen if prosumer 2 changes 66% of their electric car load at timestep 1 to timestep 1+1\n",
            "Pcons[0][1] = Pcons[0][1]*(100-66)/100 \\nPcons[0+1][1] =Pcons[0+1][1] + Pcons[0][1]*66/100\n",
            "What's the new cost of the community if prosumer 1 shifts 5% of their load at timestep 2 to timestep 2+1\n",
            "Pcons[1][0] = Pcons[1][0]*(100-5)/100 \\nPcons[1+1][0] =Pcons[1+1][0] + Pcons[1][0]*5/100\n",
            "What's the new cost of the community if prosumer 4 shifts 55% of their load at timestep 1 to timestep 1+1\n",
            "Pcons[0][3] = Pcons[0][3]*(100-55)/100 \\nPcons[0+1][3] =Pcons[0+1][3] + Pcons[0][3]*55/100\n",
            "What's the new state of battery of prosumer 4 if the prosumer shifts 68% of their load at timestep 1 to timestep 1+1\n",
            "Pcons[0][3] = Pcons[0][3]*(100-68)/100 \\nPcons[0+1][3] =Pcons[0+1][3] + Pcons[0][3]*68/100\n",
            "What's the new state of battery of prosumer 1 if the prosumer shifts 86% of their load at timestep 2 to timestep 2+1\n",
            "Pcons[1][0] = Pcons[1][0]*(100-86)/100 \\nPcons[1+1][0] =Pcons[1+1][0] + Pcons[1][0]*86/100\n",
            "What's the new state of battery of the community if prosumer 3 shifts 42% of their load at timestep 1 to timestep 1+1\n",
            "Pcons[0][2] = Pcons[0][2]*(100-42)/100 \\nPcons[0+1][2] =Pcons[0+1][2] + Pcons[0][2]*42/100\n",
            "What's the new state of battery of the community if prosumer 2 shifts 18% of their load at 2 pm to 3 pm\n",
            "Pcons[1][1] = Pcons[1][1]*(100-18)/100 \\nPcons[2][1] =Pcons[2][1] + Pcons[1][1]*18/100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# In-context learning examples.\n",
        "from tools import *\n",
        "\n",
        "icl_db = \"../benchmark/application/Dataset/questions_db_v2.csv\"\n",
        "example_qa_code = icl_code_generator(icl_db)\n",
        "#example_qa_interpreter = icl_interpreter(icl_db)\n",
        "\n",
        "print(example_qa_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5a7d7e",
      "metadata": {
        "id": "5a5a7d7e"
      },
      "source": [
        "Now, let's create an Unbiased Cathode agent and also a user.\n",
        "\n",
        "For the Unbiased Cathode agent, we only allow \"debug_times\" to be 1, which means it can debug its answer once if it encountered errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aec49fe5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restricted license - for non-production use only - expires 2024-10-28\n",
            "SOLVING\n",
            "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
            "\n",
            "CPU model: Apple M2 Pro\n",
            "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
            "\n",
            "Optimize a model with 135 rows, 69 columns and 236 nonzeros\n",
            "Model fingerprint: 0xe469aa7b\n",
            "Variable types: 54 continuous, 15 integer (15 binary)\n",
            "Coefficient statistics:\n",
            "  Matrix range     [1e+00, 1e+07]\n",
            "  Objective range  [1e-01, 1e-01]\n",
            "  Bounds range     [1e+00, 1e+00]\n",
            "  RHS range        [3e+01, 1e+07]\n",
            "Found heuristic solution: objective -24.1111111\n",
            "Presolve removed 126 rows and 57 columns\n",
            "Presolve time: 0.00s\n",
            "Presolved: 9 rows, 12 columns, 23 nonzeros\n",
            "Found heuristic solution: objective -26.1111111\n",
            "Variable types: 9 continuous, 3 integer (3 binary)\n",
            "\n",
            "Root relaxation: cutoff, 3 iterations, 0.00 seconds (0.00 work units)\n",
            "\n",
            "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
            " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
            "\n",
            "     0     0     cutoff    0       -26.11111  -26.11111  0.00%     -    0s\n",
            "\n",
            "Explored 1 nodes (3 simplex iterations) in 0.02 seconds (0.00 work units)\n",
            "Thread count was 10 (of 10 available processors)\n",
            "\n",
            "Solution count 2: -26.1111 -24.1111 \n",
            "No other solutions better than -26.1111\n",
            "\n",
            "Optimal solution found (tolerance 1.00e-04)\n",
            "Best objective -2.611111111111e+01, best bound -2.611111111111e+01, gap 0.0000%\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from SGPChat.MicroGridOpt import MicroGridOptAgent\n",
        "\n",
        "agent = MicroGridOptAgent(\n",
        "    name=\"MicroGridOpt Example\",\n",
        "    source_code=code,\n",
        "    debug_times=1,\n",
        "    example_qa_coder=example_qa_code,\n",
        "    example_qa_interpreter=\"\",\n",
        "    llm_config={\n",
        "        \"request_timeout\": 600,\n",
        "        \"seed\": 42,\n",
        "        \"config_list\": config_list,\n",
        "    }\n",
        ")\n",
        "\n",
        "user = UserProxyAgent(\n",
        "    \"user\", max_consecutive_auto_reply=0,\n",
        "    human_input_mode=\"NEVER\", code_execution_config=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd615e87",
      "metadata": {
        "id": "bd615e87"
      },
      "source": [
        "Now, let's create a user's question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "24a76f67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24a76f67",
        "outputId": "2399e32e-fe3f-429f-9c40-fcc75605741d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#user.initiate_chat(agent, message=\"At timestep 2 if the community's load increases by 500%, what would be the profit?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33muser\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "What would be the profit if the community exports are smaller than this amount of power [10,30,20] to the grid?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "Answer Code:\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "```python\n",
            "for t in range(m):\n",
            "    model.addConstr(Pexp[t] <= np.array([10,30,20])[t])\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "for t in range(m):\n",
            "    model.addConstr(Pexp[t] <= np.array([10,30,20])[t])\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33msafeguard\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "SAFE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "CODE TO BE EXECUTED\n",
            "import gurobipy as gp\n",
            "from gurobipy import GRB\n",
            "import numpy as np\n",
            "\n",
            "# Define all parameters\n",
            "m = 3  # 5 timesteps\n",
            "n = 4  # 6 prosumers\n",
            "Pprod = np.array([[65, 45, 36, 25],\n",
            "                  [60, 40, 30, 27],\n",
            "                  [69, 44, 31, 26]])\n",
            "\n",
            "Pcons = np.array([[10, 30, 20, 25],\n",
            "                  [13, 24, 20, 25],\n",
            "                  [25, 26, 20, 25]])\n",
            "\n",
            "PriceEx = 0.10  # Price of exported power from the paper euro\n",
            "PriceImp = 0.13  # Price of imported power from the paper\n",
            "\n",
            "Dt = 3 * 60  # 300 seconds m*60s, timeslots*60s\n",
            "\n",
            "SoEmin = [1800] * m  # minimum of SoE (Energy ws)\n",
            "SoEmax = [4800] * m  # maximum of SoE  (Energy ws)\n",
            "\n",
            "Bch_prev = [0, 0, 0, 0]  # Power(w) initialize Battery charge level to zero\n",
            "Bdis_prev = [0, 0, 0, 0]  # Power(w) initialize battery discharge level to zero\n",
            "\n",
            "SoEprev = np.array([2800, 3400, 2500, 3200])  # i(Energy ws) initialize SoE to previous timestep values\n",
            "\n",
            "capacity = 6000  # maximum capacity of the battery (Energy ws)\n",
            "\n",
            "Kch = (0.8 * capacity) / Dt  # 40% charging limit Energy/time > Power\n",
            "Kdis = (0.8 * capacity) / Dt  # 40% discharging limit Energy/time => Power\n",
            "\n",
            "# upper and lower bounds\n",
            "UB_x = 10000000  # maximum import\n",
            "UB_y = 10000000  # maximum export\n",
            "\n",
            "# Create a model object\n",
            "model = gp.Model('model')\n",
            "\n",
            "# OPTIGUIDE *** CODE GOES HERE\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "\n",
            "# Create variables\n",
            "# decision variables\n",
            "Pimp = model.addVars(m, name=\"Pimp\")  # Imported Power\n",
            "Pexp = model.addVars(m, name=\"Pexp\")  # Exported Power\n",
            "Bch = model.addVars(m, n, name=\"Bch\")  # Charge the battery\n",
            "Bdis = model.addVars(m, n, name=\"Bdis\")  # Discharge the battery\n",
            "SoE = model.addVars(m, n, name=\"SoE\")  # State of Energy (of the battery)\n",
            "b = model.addVars(m, vtype=GRB.BINARY, name=\"b\")  # binary variable\n",
            "c = model.addVars(m, n, vtype=GRB.BINARY, name=\"c\")  # binary variable\n",
            "SoEnext = model.addVars(m, n, name=\"SoEnext\")  # State of Energy of the battery in the next time timeslot\n",
            "\n",
            "# Define the objective function\n",
            "model.setObjective((PriceImp * Pimp.sum() - PriceEx * Pexp.sum()), GRB.MINIMIZE)\n",
            "\n",
            "# Constraints\n",
            "\n",
            "# 1. Energy balance constraint\n",
            "for t in range(m):\n",
            "    model.addConstr(\n",
            "        gp.quicksum(Pprod[t, i] for i in range(n)) - Bch.sum(t, '*') + Bdis.sum(t, '*') + Pimp[t] - Pexp[t] ==\n",
            "        np.sum(Pcons[t]))\n",
            "\n",
            "# 2. No import and export at the same time constraint\n",
            "for t in range(m):\n",
            "    model.addConstr(Pimp[t] <= (1 - b[t]) * UB_x)\n",
            "    model.addConstr(Pexp[t] <= b[t] * UB_y)\n",
            "    model.addConstr(Pimp[t] >= 0)\n",
            "    model.addConstr(Pexp[t] >= 0)\n",
            "\n",
            "# ESS constraints, i.e., battery constraints\n",
            "model.addConstrs(SoE[0, i] == SoEprev[i] for i in range(n))  # initialize the state of Energy of the battery\n",
            "model.addConstrs(SoEnext[t, i] == SoE[t, i] + (Bch[t, i] - Bdis[t, i]) * Dt for t in range(m) for i in range(n))\n",
            "model.addConstrs(SoE[t, i] == SoEnext[t - 1, i] for t in range(1, m - 1) for i in range(n))\n",
            "model.addConstrs(SoE[m - 1, i] == SoEnext[m - 2, i] for i in range(n))\n",
            "\n",
            "model.addConstrs(SoEnext[t, i] <= SoEmax[t] for t in range(m) for i in range(n))\n",
            "model.addConstrs(SoEnext[t, i] >= SoEmin[t] for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bch[t, i] >= 0 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bch[t, i] <= Kch for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bdis[t, i] >= 0 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bdis[t, i] <= Kdis for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bch[t, i] <= (1 - c[t, i]) * 100000 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bdis[t, i] <= c[t, i] * 100000 for t in range(m) for i in range(n))\n",
            "\n",
            "for t in range(m):\n",
            "    model.addConstr(Pexp[t] <= np.array([10,30,20])[t])\n",
            "\n",
            "\n",
            "# Solve the problem using Gurobi solver\n",
            "print('SOLVING')\n",
            "model.optimize()\n",
            "\n",
            "'''\n",
            "# Get the results\n",
            "Pimport = np.array([Pimp[t] for t in range(m)])\n",
            "Pexport = np.array([Pexp[t] for t in range(m)])\n",
            "Bcharge = np.array([[Bch[t, i] for i in range(n)] for t in range(m)])\n",
            "Bdischarge = np.array([[Bdis[t, i]for i in range(n)] for t in range(m)])\n",
            "Soe = np.array([[SoE[t, i] for i in range(n)] for t in range(m)])\n",
            "soenext = np.array([[SoEnext[t, i] for i in range(n)] for t in range(m)])\n",
            "\n",
            "# Print results\n",
            "print(\"PV Production\", Pprod)\n",
            "print(\"Load\", Pcons)\n",
            "print(\"############\")\n",
            "#print(\"Objective value:\", obj_value)\n",
            "print(\"Import:\", Pimport)\n",
            "print(\"Export:\", Pexport)\n",
            "print(\"Charge Battery:\", Bcharge)\n",
            "print(\"Discharge Battery:\", Bdischarge)\n",
            "print(\"SoE:\", Soe)\n",
            "print(\"SoEnext:\", soenext)\n",
            "'''\n",
            "\n",
            "m = model\n",
            "\n",
            "SOLVING\n",
            "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
            "\n",
            "CPU model: Apple M2 Pro\n",
            "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
            "\n",
            "Optimize a model with 138 rows, 69 columns and 239 nonzeros\n",
            "Model fingerprint: 0x03fb0899\n",
            "Variable types: 54 continuous, 15 integer (15 binary)\n",
            "Coefficient statistics:\n",
            "  Matrix range     [1e+00, 1e+07]\n",
            "  Objective range  [1e-01, 1e-01]\n",
            "  Bounds range     [1e+00, 1e+00]\n",
            "  RHS range        [1e+01, 1e+07]\n",
            "Presolve removed 93 rows and 12 columns\n",
            "Presolve time: 0.00s\n",
            "\n",
            "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
            "Thread count was 1 (of 10 available processors)\n",
            "\n",
            "Solution count 0\n",
            "\n",
            "Model is infeasible or unbounded\n",
            "Best objective -, best bound -, gap -\n",
            "IIS computation: initial model status unknown, solving to determine model status\n",
            "Presolve removed 93 rows and 12 columns\n",
            "Presolve time: 0.00s\n",
            "\n",
            "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
            "Thread count was 1 (of 10 available processors)\n",
            "\n",
            "Solution count 0\n",
            "\n",
            "Model is infeasible\n",
            "Best objective -, best bound -, gap -\n",
            "\n",
            "Computing Irreducible Inconsistent Subsystem (IIS)...\n",
            "\n",
            "           Constraints          |            Bounds           |  Runtime\n",
            "      Min       Max     Guess   |   Min       Max     Guess   |\n",
            "--------------------------------------------------------------------------\n",
            "        0       138         -         0        54         -           0s\n",
            "       34        34        34         3         3         3           0s\n",
            "\n",
            "IIS computed: 34 constraints, 3 bounds\n",
            "IIS runtime: 0.01 seconds (0.00 work units)\n",
            "inf_or_unbound\n",
            "Conflicting Constraints:\n",
            "['R0', 'R1', 'R2', 'R15', 'R16', 'R17', 'R18', 'R19', 'R20', 'R21', 'R22', 'R23', 'R24', 'R25', 'R26', 'R27', 'R28', 'R29', 'R30', 'R31', 'R32', 'R33', 'R34', 'R35', 'R36', 'R37', 'R38', 'R47', 'R48', 'R49', 'R50', 'R135', 'R136', 'R137']\n",
            "\u001b[33minf_or_unbound\n",
            "Conflicting Constraints:\n",
            "['R0', 'R1', 'R2', 'R15', 'R16', 'R17', 'R18', 'R19', 'R20', 'R21', 'R22', 'R23', 'R24', 'R25', 'R26', 'R27', 'R28', 'R29', 'R30', 'R31', 'R32', 'R33', 'R34', 'R35', 'R36', 'R37', 'R38', 'R47', 'R48', 'R49', 'R50', 'R135', 'R136', 'R137']\u001b[0m\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "Here are the execution results: inf_or_unbound\n",
            "Conflicting Constraints:\n",
            "['R0', 'R1', 'R2', 'R15', 'R16', 'R17', 'R18', 'R19', 'R20', 'R21', 'R22', 'R23', 'R24', 'R25', 'R26', 'R27', 'R28', 'R29', 'R30', 'R31', 'R32', 'R33', 'R34', 'R35', 'R36', 'R37', 'R38', 'R47', 'R48', 'R49', 'R50', 'R135', 'R136', 'R137']\n",
            "\n",
            "Can you organize these information to a human readable answer?\n",
            "Remember to compare the new results to the original results you obtained in the\n",
            "beginning.\n",
            "\n",
            "A positive objective value reflects a cost. So if the outcome of the optimization is positive use the word cost instead of profit. \n",
            "A negative objective value reflects a profit. When the result is negative do not show the minus sign.\n",
            "\n",
            "If the problem is infeasible, elaborate on the specific constraints that are violated.\n",
            "If the problem is unbounded, elaborate on the specific bounds that are violated.\n",
            "--- HUMAN READABLE ANSWER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "The problem you defined is unbounded, which means that you can make infinite profits under the conditions specified. \n",
            "\n",
            "Here, the specific constraints that resulted in conflict include energy balance constraints and constraints on both import and export power. Specifically, forcing the exported power to be smaller than the amounts you provided [10,30,20] at each time step contradicted with the model's attempt to balance energy production and consumption, and limitations on import/export power.\n",
            "\n",
            "In other words, you can't simply minimize exported power without affecting other aspects of the energy supply and usage. More complex adjustments to the import, battery charging/discharging rates, or other variables may be necessary to find a feasible solution. Thus, it is not possible to calculate a profit under such conditions.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to user):\n",
            "\n",
            "The problem you defined is unbounded, which means that you can make infinite profits under the conditions specified. \n",
            "\n",
            "Here, the specific constraints that resulted in conflict include energy balance constraints and constraints on both import and export power. Specifically, forcing the exported power to be smaller than the amounts you provided [10,30,20] at each time step contradicted with the model's attempt to balance energy production and consumption, and limitations on import/export power.\n",
            "\n",
            "In other words, you can't simply minimize exported power without affecting other aspects of the energy supply and usage. More complex adjustments to the import, battery charging/discharging rates, or other variables may be necessary to find a feasible solution. Thus, it is not possible to calculate a profit under such conditions.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#user.initiate_chat(agent, message=\"What would be the profit if the community exports are smaller than this amount of power [10,30,20] to the grid?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33muser\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "What should be the community's minimum load to get a cost = 0?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "Answer Code:\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "```python\n",
            "model.addConstr((PriceImp*Pimp.sum() - PriceEx * Pexp.sum()) == 0)\n",
            "model.optimize()\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "model.addConstr((PriceImp*Pimp.sum() - PriceEx * Pexp.sum()) == 0)\n",
            "model.optimize()\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33msafeguard\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "SAFE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "CODE TO BE EXECUTED\n",
            "import gurobipy as gp\n",
            "from gurobipy import GRB\n",
            "import numpy as np\n",
            "\n",
            "# Define all parameters\n",
            "m = 3  # 5 timesteps\n",
            "n = 4  # 6 prosumers\n",
            "Pprod = np.array([[65, 45, 36, 25],\n",
            "                  [60, 40, 30, 27],\n",
            "                  [69, 44, 31, 26]])\n",
            "\n",
            "Pcons = np.array([[10, 30, 20, 25],\n",
            "                  [13, 24, 20, 25],\n",
            "                  [25, 26, 20, 25]])\n",
            "\n",
            "PriceEx = 0.10  # Price of exported power from the paper euro\n",
            "PriceImp = 0.13  # Price of imported power from the paper\n",
            "\n",
            "Dt = 3 * 60  # 300 seconds m*60s, timeslots*60s\n",
            "\n",
            "SoEmin = [1800] * m  # minimum of SoE (Energy ws)\n",
            "SoEmax = [4800] * m  # maximum of SoE  (Energy ws)\n",
            "\n",
            "Bch_prev = [0, 0, 0, 0]  # Power(w) initialize Battery charge level to zero\n",
            "Bdis_prev = [0, 0, 0, 0]  # Power(w) initialize battery discharge level to zero\n",
            "\n",
            "SoEprev = np.array([2800, 3400, 2500, 3200])  # i(Energy ws) initialize SoE to previous timestep values\n",
            "\n",
            "capacity = 6000  # maximum capacity of the battery (Energy ws)\n",
            "\n",
            "Kch = (0.8 * capacity) / Dt  # 40% charging limit Energy/time > Power\n",
            "Kdis = (0.8 * capacity) / Dt  # 40% discharging limit Energy/time => Power\n",
            "\n",
            "# upper and lower bounds\n",
            "UB_x = 10000000  # maximum import\n",
            "UB_y = 10000000  # maximum export\n",
            "\n",
            "# Create a model object\n",
            "model = gp.Model('model')\n",
            "\n",
            "# OPTIGUIDE *** CODE GOES HERE\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "\n",
            "# Create variables\n",
            "# decision variables\n",
            "Pimp = model.addVars(m, name=\"Pimp\")  # Imported Power\n",
            "Pexp = model.addVars(m, name=\"Pexp\")  # Exported Power\n",
            "Bch = model.addVars(m, n, name=\"Bch\")  # Charge the battery\n",
            "Bdis = model.addVars(m, n, name=\"Bdis\")  # Discharge the battery\n",
            "SoE = model.addVars(m, n, name=\"SoE\")  # State of Energy (of the battery)\n",
            "b = model.addVars(m, vtype=GRB.BINARY, name=\"b\")  # binary variable\n",
            "c = model.addVars(m, n, vtype=GRB.BINARY, name=\"c\")  # binary variable\n",
            "SoEnext = model.addVars(m, n, name=\"SoEnext\")  # State of Energy of the battery in the next time timeslot\n",
            "\n",
            "# Define the objective function\n",
            "model.setObjective((PriceImp * Pimp.sum() - PriceEx * Pexp.sum()), GRB.MINIMIZE)\n",
            "\n",
            "# Constraints\n",
            "\n",
            "# 1. Energy balance constraint\n",
            "for t in range(m):\n",
            "    model.addConstr(\n",
            "        gp.quicksum(Pprod[t, i] for i in range(n)) - Bch.sum(t, '*') + Bdis.sum(t, '*') + Pimp[t] - Pexp[t] ==\n",
            "        np.sum(Pcons[t]))\n",
            "\n",
            "# 2. No import and export at the same time constraint\n",
            "for t in range(m):\n",
            "    model.addConstr(Pimp[t] <= (1 - b[t]) * UB_x)\n",
            "    model.addConstr(Pexp[t] <= b[t] * UB_y)\n",
            "    model.addConstr(Pimp[t] >= 0)\n",
            "    model.addConstr(Pexp[t] >= 0)\n",
            "\n",
            "# ESS constraints, i.e., battery constraints\n",
            "model.addConstrs(SoE[0, i] == SoEprev[i] for i in range(n))  # initialize the state of Energy of the battery\n",
            "model.addConstrs(SoEnext[t, i] == SoE[t, i] + (Bch[t, i] - Bdis[t, i]) * Dt for t in range(m) for i in range(n))\n",
            "model.addConstrs(SoE[t, i] == SoEnext[t - 1, i] for t in range(1, m - 1) for i in range(n))\n",
            "model.addConstrs(SoE[m - 1, i] == SoEnext[m - 2, i] for i in range(n))\n",
            "\n",
            "model.addConstrs(SoEnext[t, i] <= SoEmax[t] for t in range(m) for i in range(n))\n",
            "model.addConstrs(SoEnext[t, i] >= SoEmin[t] for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bch[t, i] >= 0 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bch[t, i] <= Kch for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bdis[t, i] >= 0 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bdis[t, i] <= Kdis for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bch[t, i] <= (1 - c[t, i]) * 100000 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bdis[t, i] <= c[t, i] * 100000 for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstr((PriceImp*Pimp.sum() - PriceEx * Pexp.sum()) == 0)\n",
            "model.optimize()\n",
            "\n",
            "\n",
            "# Solve the problem using Gurobi solver\n",
            "print('SOLVING')\n",
            "model.optimize()\n",
            "\n",
            "'''\n",
            "# Get the results\n",
            "Pimport = np.array([Pimp[t] for t in range(m)])\n",
            "Pexport = np.array([Pexp[t] for t in range(m)])\n",
            "Bcharge = np.array([[Bch[t, i] for i in range(n)] for t in range(m)])\n",
            "Bdischarge = np.array([[Bdis[t, i]for i in range(n)] for t in range(m)])\n",
            "Soe = np.array([[SoE[t, i] for i in range(n)] for t in range(m)])\n",
            "soenext = np.array([[SoEnext[t, i] for i in range(n)] for t in range(m)])\n",
            "\n",
            "# Print results\n",
            "print(\"PV Production\", Pprod)\n",
            "print(\"Load\", Pcons)\n",
            "print(\"############\")\n",
            "#print(\"Objective value:\", obj_value)\n",
            "print(\"Import:\", Pimport)\n",
            "print(\"Export:\", Pexport)\n",
            "print(\"Charge Battery:\", Bcharge)\n",
            "print(\"Discharge Battery:\", Bdischarge)\n",
            "print(\"SoE:\", Soe)\n",
            "print(\"SoEnext:\", soenext)\n",
            "'''\n",
            "\n",
            "m = model\n",
            "\n",
            "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
            "\n",
            "CPU model: Apple M2 Pro\n",
            "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
            "\n",
            "Optimize a model with 136 rows, 69 columns and 242 nonzeros\n",
            "Model fingerprint: 0x18219e06\n",
            "Variable types: 54 continuous, 15 integer (15 binary)\n",
            "Coefficient statistics:\n",
            "  Matrix range     [1e-01, 1e+07]\n",
            "  Objective range  [1e-01, 1e-01]\n",
            "  Bounds range     [1e+00, 1e+00]\n",
            "  RHS range        [3e+01, 1e+07]\n",
            "Presolve removed 90 rows and 13 columns\n",
            "Presolve time: 0.00s\n",
            "\n",
            "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
            "Thread count was 1 (of 10 available processors)\n",
            "\n",
            "Solution count 0\n",
            "\n",
            "Model is infeasible or unbounded\n",
            "Best objective -, best bound -, gap -\n",
            "SOLVING\n",
            "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
            "\n",
            "CPU model: Apple M2 Pro\n",
            "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
            "\n",
            "Optimize a model with 136 rows, 69 columns and 242 nonzeros\n",
            "Model fingerprint: 0x18219e06\n",
            "Variable types: 54 continuous, 15 integer (15 binary)\n",
            "Coefficient statistics:\n",
            "  Matrix range     [1e-01, 1e+07]\n",
            "  Objective range  [1e-01, 1e-01]\n",
            "  Bounds range     [1e+00, 1e+00]\n",
            "  RHS range        [3e+01, 1e+07]\n",
            "Presolve removed 90 rows and 13 columns\n",
            "Presolve time: 0.00s\n",
            "\n",
            "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
            "Thread count was 1 (of 10 available processors)\n",
            "\n",
            "Solution count 0\n",
            "\n",
            "Model is infeasible or unbounded\n",
            "Best objective -, best bound -, gap -\n",
            "IIS computation: initial model status unknown, solving to determine model status\n",
            "Presolve removed 90 rows and 13 columns\n",
            "Presolve time: 0.00s\n",
            "\n",
            "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
            "Thread count was 1 (of 10 available processors)\n",
            "\n",
            "Solution count 0\n",
            "\n",
            "Model is infeasible\n",
            "Best objective -, best bound -, gap -\n",
            "\n",
            "Computing Irreducible Inconsistent Subsystem (IIS)...\n",
            "\n",
            "           Constraints          |            Bounds           |  Runtime\n",
            "      Min       Max     Guess   |   Min       Max     Guess   |\n",
            "--------------------------------------------------------------------------\n",
            "        0       136         -         0        54         -           0s\n",
            "       38        38        38         9         9         9           0s\n",
            "\n",
            "IIS computed: 38 constraints, 9 bounds\n",
            "IIS runtime: 0.07 seconds (0.03 work units)\n",
            "inf_or_unbound\n",
            "Conflicting Constraints:\n",
            "['R0', 'R1', 'R2', 'R3', 'R4', 'R7', 'R8', 'R11', 'R12', 'R16', 'R17', 'R20', 'R21', 'R24', 'R28', 'R29', 'R30', 'R32', 'R36', 'R37', 'R38', 'R41', 'R48', 'R49', 'R50', 'R56', 'R57', 'R58', 'R75', 'R76', 'R77', 'R78', 'R79', 'R81', 'R82', 'R83', 'R108', 'R135']\n",
            "\u001b[33minf_or_unbound\n",
            "Conflicting Constraints:\n",
            "['R0', 'R1', 'R2', 'R3', 'R4', 'R7', 'R8', 'R11', 'R12', 'R16', 'R17', 'R20', 'R21', 'R24', 'R28', 'R29', 'R30', 'R32', 'R36', 'R37', 'R38', 'R41', 'R48', 'R49', 'R50', 'R56', 'R57', 'R58', 'R75', 'R76', 'R77', 'R78', 'R79', 'R81', 'R82', 'R83', 'R108', 'R135']\u001b[0m\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "Here are the execution results: inf_or_unbound\n",
            "Conflicting Constraints:\n",
            "['R0', 'R1', 'R2', 'R3', 'R4', 'R7', 'R8', 'R11', 'R12', 'R16', 'R17', 'R20', 'R21', 'R24', 'R28', 'R29', 'R30', 'R32', 'R36', 'R37', 'R38', 'R41', 'R48', 'R49', 'R50', 'R56', 'R57', 'R58', 'R75', 'R76', 'R77', 'R78', 'R79', 'R81', 'R82', 'R83', 'R108', 'R135']\n",
            "\n",
            "Can you organize these information to a human readable answer?\n",
            "Remember to compare the new results to the original results you obtained in the\n",
            "beginning.\n",
            "\n",
            "A positive objective value reflects a cost. So if the outcome of the optimization is positive use the word cost instead of profit. \n",
            "A negative objective value reflects a profit. When the result is negative do not show the minus sign.\n",
            "\n",
            "If the problem is infeasible, elaborate on the specific constraints that are violated.\n",
            "If the problem is unbounded, elaborate on the specific bounds that are violated.\n",
            "--- HUMAN READABLE ANSWER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "The problem is not feasible when we impose a new constraint that the community's cost should be equal to zero. Multiple constraints including 'R0', 'R1', 'R2', 'R3', 'R4', 'R7', 'R8', 'R11', 'R12', 'R16', 'R17', 'R20', 'R21', 'R24', 'R28', 'R29', 'R30', 'R32', 'R36', 'R37', 'R38', 'R41', 'R48', 'R49', 'R50', 'R56', 'R57', 'R58', 'R75', 'R76', 'R77', 'R78', 'R79', 'R81', 'R82', 'R83', 'R108', 'R135' are conflicting with the new constraint. This mainly suggests that the community's configuration cannot allow for a cost of zero due to the inherent constraints about power import and export, battery charges and discharges, and the state of energy within this system. If you want to achieve zero cost, the community may need to adjust its configuration, such as changing power consumption and production settings or adjusting battery operations.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to user):\n",
            "\n",
            "The problem is not feasible when we impose a new constraint that the community's cost should be equal to zero. Multiple constraints including 'R0', 'R1', 'R2', 'R3', 'R4', 'R7', 'R8', 'R11', 'R12', 'R16', 'R17', 'R20', 'R21', 'R24', 'R28', 'R29', 'R30', 'R32', 'R36', 'R37', 'R38', 'R41', 'R48', 'R49', 'R50', 'R56', 'R57', 'R58', 'R75', 'R76', 'R77', 'R78', 'R79', 'R81', 'R82', 'R83', 'R108', 'R135' are conflicting with the new constraint. This mainly suggests that the community's configuration cannot allow for a cost of zero due to the inherent constraints about power import and export, battery charges and discharges, and the state of energy within this system. If you want to achieve zero cost, the community may need to adjust its configuration, such as changing power consumption and production settings or adjusting battery operations.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "user.initiate_chat(agent, message=\"What should be the community's minimum load to get a cost = 0?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33muser\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "What would happen if I shift 50% of the load at t=1 to t=2\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "Answer Code:\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "```python\n",
            "# Decrease 50% load of timestep 1\n",
            "Pcons[0] = Pcons[0] * 0.5\n",
            "\n",
            "# Increase 50% load of timestep 1 to timestep 2\n",
            "Pcons[1] = Pcons[1] + Pcons[0] * 0.5\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "# Decrease 50% load of timestep 1\n",
            "Pcons[0] = Pcons[0] * 0.5\n",
            "\n",
            "# Increase 50% load of timestep 1 to timestep 2\n",
            "Pcons[1] = Pcons[1] + Pcons[0] * 0.5\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33msafeguard\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "SAFE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "CODE TO BE EXECUTED\n",
            "import gurobipy as gp\n",
            "from gurobipy import GRB\n",
            "import numpy as np\n",
            "\n",
            "# Define all parameters\n",
            "m = 3  # 5 timesteps\n",
            "n = 4  # 6 prosumers\n",
            "Pprod = np.array([[65, 45, 36, 25],\n",
            "                  [60, 40, 30, 27],\n",
            "                  [69, 44, 31, 26]])\n",
            "\n",
            "Pcons = np.array([[10, 30, 20, 25],\n",
            "                  [13, 24, 20, 25],\n",
            "                  [25, 26, 20, 25]])\n",
            "\n",
            "PriceEx = 0.10  # Price of exported power from the paper euro\n",
            "PriceImp = 0.13  # Price of imported power from the paper\n",
            "\n",
            "Dt = 3 * 60  # 300 seconds m*60s, timeslots*60s\n",
            "\n",
            "SoEmin = [1800] * m  # minimum of SoE (Energy ws)\n",
            "SoEmax = [4800] * m  # maximum of SoE  (Energy ws)\n",
            "\n",
            "Bch_prev = [0, 0, 0, 0]  # Power(w) initialize Battery charge level to zero\n",
            "Bdis_prev = [0, 0, 0, 0]  # Power(w) initialize battery discharge level to zero\n",
            "\n",
            "SoEprev = np.array([2800, 3400, 2500, 3200])  # i(Energy ws) initialize SoE to previous timestep values\n",
            "\n",
            "capacity = 6000  # maximum capacity of the battery (Energy ws)\n",
            "\n",
            "Kch = (0.8 * capacity) / Dt  # 40% charging limit Energy/time > Power\n",
            "Kdis = (0.8 * capacity) / Dt  # 40% discharging limit Energy/time => Power\n",
            "\n",
            "# upper and lower bounds\n",
            "UB_x = 10000000  # maximum import\n",
            "UB_y = 10000000  # maximum export\n",
            "\n",
            "# Create a model object\n",
            "model = gp.Model('model')\n",
            "\n",
            "# OPTIGUIDE *** CODE GOES HERE\n",
            "# Decrease 50% load of timestep 1\n",
            "Pcons[0] = Pcons[0] * 0.5\n",
            "\n",
            "# Increase 50% load of timestep 1 to timestep 2\n",
            "Pcons[1] = Pcons[1] + Pcons[0] * 0.5\n",
            "\n",
            "# Create variables\n",
            "# decision variables\n",
            "Pimp = model.addVars(m, name=\"Pimp\")  # Imported Power\n",
            "Pexp = model.addVars(m, name=\"Pexp\")  # Exported Power\n",
            "Bch = model.addVars(m, n, name=\"Bch\")  # Charge the battery\n",
            "Bdis = model.addVars(m, n, name=\"Bdis\")  # Discharge the battery\n",
            "SoE = model.addVars(m, n, name=\"SoE\")  # State of Energy (of the battery)\n",
            "b = model.addVars(m, vtype=GRB.BINARY, name=\"b\")  # binary variable\n",
            "c = model.addVars(m, n, vtype=GRB.BINARY, name=\"c\")  # binary variable\n",
            "SoEnext = model.addVars(m, n, name=\"SoEnext\")  # State of Energy of the battery in the next time timeslot\n",
            "\n",
            "# Define the objective function\n",
            "model.setObjective((PriceImp * Pimp.sum() - PriceEx * Pexp.sum()), GRB.MINIMIZE)\n",
            "\n",
            "# Constraints\n",
            "\n",
            "# 1. Energy balance constraint\n",
            "for t in range(m):\n",
            "    model.addConstr(\n",
            "        gp.quicksum(Pprod[t, i] for i in range(n)) - Bch.sum(t, '*') + Bdis.sum(t, '*') + Pimp[t] - Pexp[t] ==\n",
            "        np.sum(Pcons[t]))\n",
            "\n",
            "# 2. No import and export at the same time constraint\n",
            "for t in range(m):\n",
            "    model.addConstr(Pimp[t] <= (1 - b[t]) * UB_x)\n",
            "    model.addConstr(Pexp[t] <= b[t] * UB_y)\n",
            "    model.addConstr(Pimp[t] >= 0)\n",
            "    model.addConstr(Pexp[t] >= 0)\n",
            "\n",
            "# ESS constraints, i.e., battery constraints\n",
            "model.addConstrs(SoE[0, i] == SoEprev[i] for i in range(n))  # initialize the state of Energy of the battery\n",
            "model.addConstrs(SoEnext[t, i] == SoE[t, i] + (Bch[t, i] - Bdis[t, i]) * Dt for t in range(m) for i in range(n))\n",
            "model.addConstrs(SoE[t, i] == SoEnext[t - 1, i] for t in range(1, m - 1) for i in range(n))\n",
            "model.addConstrs(SoE[m - 1, i] == SoEnext[m - 2, i] for i in range(n))\n",
            "\n",
            "model.addConstrs(SoEnext[t, i] <= SoEmax[t] for t in range(m) for i in range(n))\n",
            "model.addConstrs(SoEnext[t, i] >= SoEmin[t] for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bch[t, i] >= 0 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bch[t, i] <= Kch for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bdis[t, i] >= 0 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bdis[t, i] <= Kdis for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bch[t, i] <= (1 - c[t, i]) * 100000 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bdis[t, i] <= c[t, i] * 100000 for t in range(m) for i in range(n))\n",
            "\n",
            "# OPTIGUIDE CONSTRAINT CODE GOES HERE\n",
            "\n",
            "\n",
            "# Solve the problem using Gurobi solver\n",
            "print('SOLVING')\n",
            "model.optimize()\n",
            "\n",
            "'''\n",
            "# Get the results\n",
            "Pimport = np.array([Pimp[t] for t in range(m)])\n",
            "Pexport = np.array([Pexp[t] for t in range(m)])\n",
            "Bcharge = np.array([[Bch[t, i] for i in range(n)] for t in range(m)])\n",
            "Bdischarge = np.array([[Bdis[t, i]for i in range(n)] for t in range(m)])\n",
            "Soe = np.array([[SoE[t, i] for i in range(n)] for t in range(m)])\n",
            "soenext = np.array([[SoEnext[t, i] for i in range(n)] for t in range(m)])\n",
            "\n",
            "# Print results\n",
            "print(\"PV Production\", Pprod)\n",
            "print(\"Load\", Pcons)\n",
            "print(\"############\")\n",
            "#print(\"Objective value:\", obj_value)\n",
            "print(\"Import:\", Pimport)\n",
            "print(\"Export:\", Pexport)\n",
            "print(\"Charge Battery:\", Bcharge)\n",
            "print(\"Discharge Battery:\", Bdischarge)\n",
            "print(\"SoE:\", Soe)\n",
            "print(\"SoEnext:\", soenext)\n",
            "'''\n",
            "\n",
            "m = model\n",
            "\n",
            "SOLVING\n",
            "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
            "\n",
            "CPU model: Apple M2 Pro\n",
            "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
            "\n",
            "Optimize a model with 135 rows, 69 columns and 236 nonzeros\n",
            "Model fingerprint: 0x339b883a\n",
            "Variable types: 54 continuous, 15 integer (15 binary)\n",
            "Coefficient statistics:\n",
            "  Matrix range     [1e+00, 1e+07]\n",
            "  Objective range  [1e-01, 1e-01]\n",
            "  Bounds range     [1e+00, 1e+00]\n",
            "  RHS range        [3e+01, 1e+07]\n",
            "Found heuristic solution: objective -26.4111111\n",
            "Presolve removed 96 rows and 18 columns\n",
            "Presolve time: 0.00s\n",
            "Presolved: 39 rows, 51 columns, 107 nonzeros\n",
            "Variable types: 38 continuous, 13 integer (13 binary)\n",
            "\n",
            "Root relaxation: objective -2.841111e+01, 25 iterations, 0.00 seconds (0.00 work units)\n",
            "\n",
            "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
            " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
            "\n",
            "*    0     0               0     -28.4111111  -28.41111  0.00%     -    0s\n",
            "\n",
            "Explored 1 nodes (25 simplex iterations) in 0.01 seconds (0.00 work units)\n",
            "Thread count was 10 (of 10 available processors)\n",
            "\n",
            "Solution count 2: -28.4111 -26.4111 \n",
            "No other solutions better than -28.4111\n",
            "\n",
            "Optimal solution found (tolerance 1.00e-04)\n",
            "Best objective -2.841111111111e+01, best bound -2.841111111111e+01, gap 0.0000%\n",
            "\u001b[33mOptimization problem solved. The objective value is: -28.41111111111112\u001b[0m\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "Here are the execution results: Optimization problem solved. The objective value is: -28.41111111111112\n",
            "\n",
            "Can you organize these information to a human readable answer?\n",
            "Remember to compare the new results to the original results you obtained in the\n",
            "beginning.\n",
            "\n",
            "A positive objective value reflects a cost. So if the outcome of the optimization is positive use the word cost instead of profit. \n",
            "A negative objective value reflects a profit. When the result is negative do not show the minus sign.\n",
            "\n",
            "If the problem is infeasible, elaborate on the specific constraints that are violated.\n",
            "If the problem is unbounded, elaborate on the specific bounds that are violated.\n",
            "--- HUMAN READABLE ANSWER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "By shifting 50% of the load from timestep 1 to timestep 2, we have increased the profit from 26.11 to 28.41. This indicates that it is more beneficial to have a larger load at timestep 2. Keep in mind, however, that this result depends heavily on other factors, such as the prices of import and export, and the available energy for each timestep.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to user):\n",
            "\n",
            "By shifting 50% of the load from timestep 1 to timestep 2, we have increased the profit from 26.11 to 28.41. This indicates that it is more beneficial to have a larger load at timestep 2. Keep in mind, however, that this result depends heavily on other factors, such as the prices of import and export, and the available energy for each timestep.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "user.initiate_chat(agent, message=\"What would happen if I shift 50% of the load at t=1 to t=2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "acec22c4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nProblems: Agent Writer does not seem to be able to interpret the results of the optimization correctly. \\nApproach: Try in-context learning there as well \\n\\n'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# next steps: - name constraints  // - have two perspectives: consumers and producers\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33muser\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "What would my cost be if the community wants the indoor temperature to remain between 20 and 25 degrees? You can look up standard loads needed to keep an average household at that temperature and add it to the imported power\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "Answer Code:\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "```python\n",
            "# Assuming standard load of a household is 30 to maintain temperature between 20 to 25 degree\n",
            "standard_load = 30\n",
            "Pimp_new = model.addVars(m, name=\"Pimp_new\")  # New Imported Power after considering temperature requirement\n",
            "model.addConstrs(Pimp_new[t] >= Pimp[t] + standard_load for t in range(m))\n",
            "\n",
            "model.setObjective((PriceImp * Pimp_new.sum() - PriceEx * Pexp.sum()), GRB.MINIMIZE)\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "# Assuming standard load of a household is 30 to maintain temperature between 20 to 25 degree\n",
            "standard_load = 30\n",
            "Pimp_new = model.addVars(m, name=\"Pimp_new\")  # New Imported Power after considering temperature requirement\n",
            "model.addConstrs(Pimp_new[t] >= Pimp[t] + standard_load for t in range(m))\n",
            "\n",
            "model.setObjective((PriceImp * Pimp_new.sum() - PriceEx * Pexp.sum()), GRB.MINIMIZE)\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33msafeguard\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "SAFE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "CODE TO BE EXECUTED\n",
            "import gurobipy as gp\n",
            "from gurobipy import GRB\n",
            "import numpy as np\n",
            "\n",
            "# Define all parameters\n",
            "m = 3  # 5 timesteps\n",
            "n = 4  # 6 prosumers\n",
            "Pprod = np.array([[65, 45, 36, 25],\n",
            "                  [60, 40, 30, 27],\n",
            "                  [69, 44, 31, 26]])\n",
            "\n",
            "Pcons = np.array([[10, 30, 20, 25],\n",
            "                  [13, 24, 20, 25],\n",
            "                  [25, 26, 20, 25]])\n",
            "\n",
            "PriceEx = 0.10  # Price of exported power from the paper euro\n",
            "PriceImp = 0.13  # Price of imported power from the paper\n",
            "\n",
            "Dt = 3 * 60  # 300 seconds m*60s, timeslots*60s\n",
            "\n",
            "SoEmin = [1800] * m  # minimum of SoE (Energy ws)\n",
            "SoEmax = [4800] * m  # maximum of SoE  (Energy ws)\n",
            "\n",
            "Bch_prev = [0, 0, 0, 0]  # Power(w) initialize Battery charge level to zero\n",
            "Bdis_prev = [0, 0, 0, 0]  # Power(w) initialize battery discharge level to zero\n",
            "\n",
            "SoEprev = np.array([2800, 3400, 2500, 3200])  # i(Energy ws) initialize SoE to previous timestep values\n",
            "\n",
            "capacity = 6000  # maximum capacity of the battery (Energy ws)\n",
            "\n",
            "Kch = (0.8 * capacity) / Dt  # 40% charging limit Energy/time > Power\n",
            "Kdis = (0.8 * capacity) / Dt  # 40% discharging limit Energy/time => Power\n",
            "\n",
            "# upper and lower bounds\n",
            "UB_x = 10000000  # maximum import\n",
            "UB_y = 10000000  # maximum export\n",
            "\n",
            "# Create a model object\n",
            "model = gp.Model('model')\n",
            "\n",
            "# OPTIGUIDE *** CODE GOES HERE\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "\n",
            "# Create variables\n",
            "# decision variables\n",
            "Pimp = model.addVars(m, name=\"Pimp\")  # Imported Power\n",
            "Pexp = model.addVars(m, name=\"Pexp\")  # Exported Power\n",
            "Bch = model.addVars(m, n, name=\"Bch\")  # Charge the battery\n",
            "Bdis = model.addVars(m, n, name=\"Bdis\")  # Discharge the battery\n",
            "SoE = model.addVars(m, n, name=\"SoE\")  # State of Energy (of the battery)\n",
            "b = model.addVars(m, vtype=GRB.BINARY, name=\"b\")  # binary variable\n",
            "c = model.addVars(m, n, vtype=GRB.BINARY, name=\"c\")  # binary variable\n",
            "SoEnext = model.addVars(m, n, name=\"SoEnext\")  # State of Energy of the battery in the next time timeslot\n",
            "\n",
            "# Define the objective function\n",
            "model.setObjective((PriceImp * Pimp.sum() - PriceEx * Pexp.sum()), GRB.MINIMIZE)\n",
            "\n",
            "# Constraints\n",
            "\n",
            "# 1. Energy balance constraint\n",
            "for t in range(m):\n",
            "    model.addConstr(\n",
            "        gp.quicksum(Pprod[t, i] for i in range(n)) - Bch.sum(t, '*') + Bdis.sum(t, '*') + Pimp[t] - Pexp[t] ==\n",
            "        np.sum(Pcons[t]))\n",
            "\n",
            "# 2. No import and export at the same time constraint\n",
            "for t in range(m):\n",
            "    model.addConstr(Pimp[t] <= (1 - b[t]) * UB_x)\n",
            "    model.addConstr(Pexp[t] <= b[t] * UB_y)\n",
            "    model.addConstr(Pimp[t] >= 0)\n",
            "    model.addConstr(Pexp[t] >= 0)\n",
            "\n",
            "# ESS constraints, i.e., battery constraints\n",
            "model.addConstrs(SoE[0, i] == SoEprev[i] for i in range(n))  # initialize the state of Energy of the battery\n",
            "model.addConstrs(SoEnext[t, i] == SoE[t, i] + (Bch[t, i] - Bdis[t, i]) * Dt for t in range(m) for i in range(n))\n",
            "model.addConstrs(SoE[t, i] == SoEnext[t - 1, i] for t in range(1, m - 1) for i in range(n))\n",
            "model.addConstrs(SoE[m - 1, i] == SoEnext[m - 2, i] for i in range(n))\n",
            "\n",
            "model.addConstrs(SoEnext[t, i] <= SoEmax[t] for t in range(m) for i in range(n))\n",
            "model.addConstrs(SoEnext[t, i] >= SoEmin[t] for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bch[t, i] >= 0 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bch[t, i] <= Kch for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bdis[t, i] >= 0 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bdis[t, i] <= Kdis for t in range(m) for i in range(n))\n",
            "\n",
            "model.addConstrs(Bch[t, i] <= (1 - c[t, i]) * 100000 for t in range(m) for i in range(n))\n",
            "model.addConstrs(Bdis[t, i] <= c[t, i] * 100000 for t in range(m) for i in range(n))\n",
            "\n",
            "# Assuming standard load of a household is 30 to maintain temperature between 20 to 25 degree\n",
            "standard_load = 30\n",
            "Pimp_new = model.addVars(m, name=\"Pimp_new\")  # New Imported Power after considering temperature requirement\n",
            "model.addConstrs(Pimp_new[t] >= Pimp[t] + standard_load for t in range(m))\n",
            "\n",
            "model.setObjective((PriceImp * Pimp_new.sum() - PriceEx * Pexp.sum()), GRB.MINIMIZE)\n",
            "\n",
            "\n",
            "# Solve the problem using Gurobi solver\n",
            "print('SOLVING')\n",
            "model.optimize()\n",
            "\n",
            "'''\n",
            "# Get the results\n",
            "Pimport = np.array([Pimp[t] for t in range(m)])\n",
            "Pexport = np.array([Pexp[t] for t in range(m)])\n",
            "Bcharge = np.array([[Bch[t, i] for i in range(n)] for t in range(m)])\n",
            "Bdischarge = np.array([[Bdis[t, i]for i in range(n)] for t in range(m)])\n",
            "Soe = np.array([[SoE[t, i] for i in range(n)] for t in range(m)])\n",
            "soenext = np.array([[SoEnext[t, i] for i in range(n)] for t in range(m)])\n",
            "\n",
            "# Print results\n",
            "print(\"PV Production\", Pprod)\n",
            "print(\"Load\", Pcons)\n",
            "print(\"############\")\n",
            "#print(\"Objective value:\", obj_value)\n",
            "print(\"Import:\", Pimport)\n",
            "print(\"Export:\", Pexport)\n",
            "print(\"Charge Battery:\", Bcharge)\n",
            "print(\"Discharge Battery:\", Bdischarge)\n",
            "print(\"SoE:\", Soe)\n",
            "print(\"SoEnext:\", soenext)\n",
            "'''\n",
            "\n",
            "m = model\n",
            "\n",
            "SOLVING\n",
            "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
            "\n",
            "CPU model: Apple M2 Pro\n",
            "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
            "\n",
            "Optimize a model with 138 rows, 72 columns and 242 nonzeros\n",
            "Model fingerprint: 0x3e787811\n",
            "Variable types: 57 continuous, 15 integer (15 binary)\n",
            "Coefficient statistics:\n",
            "  Matrix range     [1e+00, 1e+07]\n",
            "  Objective range  [1e-01, 1e-01]\n",
            "  Bounds range     [1e+00, 1e+00]\n",
            "  RHS range        [3e+01, 1e+07]\n",
            "Found heuristic solution: objective -12.4111111\n",
            "Presolve removed 129 rows and 60 columns\n",
            "Presolve time: 0.00s\n",
            "Presolved: 9 rows, 12 columns, 23 nonzeros\n",
            "Found heuristic solution: objective -14.4111111\n",
            "Variable types: 9 continuous, 3 integer (3 binary)\n",
            "\n",
            "Root relaxation: cutoff, 3 iterations, 0.00 seconds (0.00 work units)\n",
            "\n",
            "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
            " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
            "\n",
            "     0     0     cutoff    0       -14.41111  -14.41111  0.00%     -    0s\n",
            "\n",
            "Explored 1 nodes (3 simplex iterations) in 0.01 seconds (0.00 work units)\n",
            "Thread count was 10 (of 10 available processors)\n",
            "\n",
            "Solution count 2: -14.4111 -12.4111 \n",
            "No other solutions better than -14.4111\n",
            "\n",
            "Optimal solution found (tolerance 1.00e-04)\n",
            "Best objective -1.441111111111e+01, best bound -1.441111111111e+01, gap 0.0000%\n",
            "\u001b[33mOptimization problem solved. The objective value is: -14.411111111111117\u001b[0m\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "Here are the execution results: Optimization problem solved. The objective value is: -14.411111111111117\n",
            "\n",
            "Can you organize these information to a human readable answer?\n",
            "Remember to compare the new results to the original results you obtained in the\n",
            "beginning.\n",
            "\n",
            "A positive objective value reflects a cost. So if the outcome of the optimization is positive use the word cost instead of profit. \n",
            "A negative objective value reflects a profit. When the result is negative do not show the minus sign.\n",
            "\n",
            "If the problem is infeasible, elaborate on the specific constraints that are violated.\n",
            "If the problem is unbounded, elaborate on the specific bounds that are violated.\n",
            "--- HUMAN READABLE ANSWER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "The original cost to maintain the necessary power supply was -26.111111111111114 , which actually indicates a profit of 26.111111111111114 . This is due to the community exporting more power to the grid than it's importing, leading to income from selling power.\n",
            "\n",
            "However, if the community wants to maintain the indoor temperature between 20 to 25 degrees, a greater amount of power is required for each household. This increases the community's power imports substantially, which overshadows the profits from selling power. As a result, the community ends up with a cost of 14.411111111111117, rather than a profit.\n",
            "\n",
            "Specifically, the extra power required by each household to maintain the indoor temperature between 20 to 25 degrees costs more than the community can recover from selling surplus power to the grid. Therefore, it is highly recommended that each household carefully manages power consumption to minimize costs.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to user):\n",
            "\n",
            "The original cost to maintain the necessary power supply was -26.111111111111114 , which actually indicates a profit of 26.111111111111114 . This is due to the community exporting more power to the grid than it's importing, leading to income from selling power.\n",
            "\n",
            "However, if the community wants to maintain the indoor temperature between 20 to 25 degrees, a greater amount of power is required for each household. This increases the community's power imports substantially, which overshadows the profits from selling power. As a result, the community ends up with a cost of 14.411111111111117, rather than a profit.\n",
            "\n",
            "Specifically, the extra power required by each household to maintain the indoor temperature between 20 to 25 degrees costs more than the community can recover from selling surplus power to the grid. Therefore, it is highly recommended that each household carefully manages power consumption to minimize costs.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "user.initiate_chat(agent, message=\"What would my cost be if the community wants the indoor temperature to remain between 20 and 25 degrees? You can look up standard loads needed to keep an average household at that temperature and add it to the imported power\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restricted license - for non-production use only - expires 2024-10-28\n",
            "SOLVING\n",
            "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[arm])\n",
            "\n",
            "CPU model: Apple M2 Pro\n",
            "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
            "\n",
            "Optimize a model with 135 rows, 69 columns and 236 nonzeros\n",
            "Model fingerprint: 0xe469aa7b\n",
            "Variable types: 54 continuous, 15 integer (15 binary)\n",
            "Coefficient statistics:\n",
            "  Matrix range     [1e+00, 1e+07]\n",
            "  Objective range  [1e-01, 1e-01]\n",
            "  Bounds range     [1e+00, 1e+00]\n",
            "  RHS range        [3e+01, 1e+07]\n",
            "Found heuristic solution: objective -24.1111111\n",
            "Presolve removed 126 rows and 57 columns\n",
            "Presolve time: 0.00s\n",
            "Presolved: 9 rows, 12 columns, 23 nonzeros\n",
            "Found heuristic solution: objective -26.1111111\n",
            "Variable types: 9 continuous, 3 integer (3 binary)\n",
            "\n",
            "Root relaxation: cutoff, 3 iterations, 0.00 seconds (0.00 work units)\n",
            "\n",
            "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
            " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
            "\n",
            "     0     0     cutoff    0       -26.11111  -26.11111  0.00%     -    0s\n",
            "\n",
            "Explored 1 nodes (3 simplex iterations) in 0.01 seconds (0.00 work units)\n",
            "Thread count was 10 (of 10 available processors)\n",
            "\n",
            "Solution count 2: -26.1111 -24.1111 \n",
            "No other solutions better than -26.1111\n",
            "\n",
            "Optimal solution found (tolerance 1.00e-04)\n",
            "Best objective -2.611111111111e+01, best bound -2.611111111111e+01, gap 0.0000%\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from SGPChat.MicroGridOpt import MicroGridOptAgent\n",
        "\n",
        "agent = MicroGridOptAgent(\n",
        "    name=\"MicroGridOpt Example\",\n",
        "    source_code=code,\n",
        "    debug_times=1,\n",
        "    example_qa_coder=\"\",#example_qa_code,\n",
        "    example_qa_interpreter=\"\",\n",
        "    llm_config={\n",
        "        \"request_timeout\": 600,\n",
        "        \"seed\": 42,\n",
        "        \"config_list\": config_list,\n",
        "    }\n",
        ")\n",
        "\n",
        "user = UserProxyAgent(\n",
        "    \"user\", max_consecutive_auto_reply=0,\n",
        "    human_input_mode=\"NEVER\", code_execution_config=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "file_path = \"/Users/cchaabani/Documents/GitRepo/SGP-Chat/benchmark/QAs/questions_benchmark_load_shifting_pcons_processed.csv\"\n",
        "import time\n",
        "import csv\n",
        "\n",
        "data_dict = {}\n",
        "\n",
        "if os.path.exists(file_path.replace(\".csv\", \"_finalprocessed_gpt3_noicl.csv\")):\n",
        "        with open(file_path.replace(\".csv\", \"_finalprocessed_gpt3_noicl.csv\"), 'r') as csvfile:\n",
        "            csv_reader = csv.DictReader(csvfile)\n",
        "            for row in csv_reader:\n",
        "                question = row['Question']\n",
        "                data_dict[question] = {\n",
        "                    'GT Code': row['GT Code'],\n",
        "                    'GT Objective Value': row['GT Objective Value'],\n",
        "                    'SGP Code': row['SGP Code'],\n",
        "                    'SGP Objective Value': row['SGP Objective Value']\n",
        "                    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'What would happen if prosumer 2 shifts 65% of their load at timestep 2 to timestep 2+1': {'GT Code': 'Pcons[1][1] = Pcons[1][1]*(100-65)/100 \\\\nPcons[1+1][1] = Pcons[1+1][1] + Pcons[1][1]* 65/100',\n",
              "  'GT Objective Value': '-27.211111111111116',\n",
              "  'SGP Code': '# Calculate the new load shifted from timestep 2 to timestep 2+1 for prosumer 2\\nshifted_load = 0.65 * Pcons[1, 1]\\n\\n# Update the load at timestep 2 and timestep 2+1 for prosumer 2\\nPcons[1, 1] -= shifted_load  # Subtract the shifted load from timestep 2\\nPcons[2, 1] += shifted_load  # Add the shifted load to timestep 2+1',\n",
              "  'SGP Objective Value': ''},\n",
              " 'What would happen if prosumer 2 shifts 44% of their load at timestep 1 to timestep 1+1': {'GT Code': 'Pcons[0][1] = Pcons[0][1]*(100-44)/100 \\\\nPcons[0+1][1] = Pcons[0+1][1] + Pcons[0][1]* 44/100',\n",
              "  'GT Objective Value': '-26.81111111111111',\n",
              "  'SGP Code': '# OPTIGUIDE DATA CODE GOES HERE\\n# Shift 44% of load from timestep 1 to timestep 1+1 for prosumer 2\\nmodel.addConstr((Pcons[1, 1] + Pcons[2, 1]) == (Pcons[1, 1] + 0.56 * Pcons[2, 1]))',\n",
              "  'SGP Objective Value': ''}}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_dict             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33muser\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "What would happen if prosumer 3 shifts 27% of their load at timestep 1 to timestep 1+1\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "Answer Code:\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "```python\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "\n",
            "# Shift 27% of the load from timestep 1 to timestep 1+1 for prosumer 3\n",
            "new_load = 0.27 * Pcons[1, 2]\n",
            "Pcons[1, 2] -= new_load  # Reduce load at timestep 1\n",
            "Pcons[2, 2] += new_load  # Increase load at timestep 2\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "\n",
            "# Shift 27% of the load from timestep 1 to timestep 1+1 for prosumer 3\n",
            "new_load = 0.27 * Pcons[1, 2]\n",
            "Pcons[1, 2] -= new_load  # Reduce load at timestep 1\n",
            "Pcons[2, 2] += new_load  # Increase load at timestep 2\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33msafeguard\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "DANGER\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Execution out\n",
            "\n",
            "\n",
            "While running the code you suggested, I encountered the <class 'str'>:\n",
            "--- ERROR MESSAGE ---\n",
            "\n",
            "Sorry, this new code is not safe to run. I would not allow you to execute it.\n",
            "Please try to find a new way (coding) to answer the question.\n",
            "\n",
            "Please try to resolve this bug, and rewrite the code snippet.\n",
            "--- NEW CODE ---\n",
            "\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to writer):\n",
            "\n",
            "\n",
            "\n",
            "While running the code you suggested, I encountered the <class 'str'>:\n",
            "--- ERROR MESSAGE ---\n",
            "\n",
            "Sorry, this new code is not safe to run. I would not allow you to execute it.\n",
            "Please try to find a new way (coding) to answer the question.\n",
            "\n",
            "Please try to resolve this bug, and rewrite the code snippet.\n",
            "--- NEW CODE ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mwriter\u001b[0m (to MicroGridOpt Example):\n",
            "\n",
            "```python\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "\n",
            "# Shift 27% of the load from timestep 1 to timestep 1+1 for prosumer 3\n",
            "new_load = 0.27 * Pcons[1, 2]\n",
            "Pcons[1, 2] -= new_load  # Reduce load at timestep 1\n",
            "Pcons[1+1, 2] += new_load  # Increase load at timestep 1+1\n",
            "```\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[33mMicroGridOpt Example\u001b[0m (to safeguard):\n",
            "\n",
            "\n",
            "--- Code ---\n",
            "# OPTIGUIDE DATA CODE GOES HERE\n",
            "\n",
            "# Shift 27% of the load from timestep 1 to timestep 1+1 for prosumer 3\n",
            "new_load = 0.27 * Pcons[1, 2]\n",
            "Pcons[1, 2] -= new_load  # Reduce load at timestep 1\n",
            "Pcons[1+1, 2] += new_load  # Increase load at timestep 1+1\n",
            "\n",
            "--- One-Word Answer: SAFE or DANGER ---\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[flaml.autogen.oai.completion: 01-31 20:07:31] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:07:41] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:07:51] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:08:02] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:08:12] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:08:22] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:08:32] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:08:43] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:08:53] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:09:03] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n",
            "[flaml.autogen.oai.completion: 01-31 20:09:13] {236} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py\", line 206, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/Users/cchaabani/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.\n"
          ]
        },
        {
          "ename": "RateLimitError",
          "evalue": "Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/cchaabani/Documents/GitRepo/SGP-Chat/notebook/MicroGridOpt_example.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cchaabani/Documents/GitRepo/SGP-Chat/notebook/MicroGridOpt_example.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m gt_code \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mGT Code\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cchaabani/Documents/GitRepo/SGP-Chat/notebook/MicroGridOpt_example.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m gt_obj_value \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mGT Objective Value\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cchaabani/Documents/GitRepo/SGP-Chat/notebook/MicroGridOpt_example.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m user\u001b[39m.\u001b[39;49minitiate_chat(agent, message\u001b[39m=\u001b[39;49mquestion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cchaabani/Documents/GitRepo/SGP-Chat/notebook/MicroGridOpt_example.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m execution_rst \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mexecution_out\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cchaabani/Documents/GitRepo/SGP-Chat/notebook/MicroGridOpt_example.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m gpt_code \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mcode\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:521\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[1;32m    509\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 521\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:324\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    322\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 324\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    325\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:452\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
            "File \u001b[0;32m~/Documents/GitRepo/SGP-Chat/notebook/../SGPChat/MicroGridOpt.py:144\u001b[0m, in \u001b[0;36mMicroGridOptAgent.generate_reply\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_success \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m# Step 2-6: code, safeguard, and interpret\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitiate_chat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_writer, message\u001b[39m=\u001b[39;49mCODE_PROMPT)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_success:\n\u001b[1;32m    146\u001b[0m     \u001b[39m# step 7: receive interpret result\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_message(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_writer)[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:521\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[1;32m    509\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 521\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:324\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    322\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 324\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    325\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:454\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    452\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_messages[sender], sender\u001b[39m=\u001b[39msender)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender, silent\u001b[39m=\u001b[39;49msilent)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:324\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    322\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 324\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    325\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:454\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    452\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_messages[sender], sender\u001b[39m=\u001b[39msender)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender, silent\u001b[39m=\u001b[39;49msilent)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:324\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    322\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 324\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    325\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:454\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    452\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_messages[sender], sender\u001b[39m=\u001b[39msender)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender, silent\u001b[39m=\u001b[39;49msilent)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:324\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    322\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 324\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    325\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:452\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
            "File \u001b[0;32m~/Documents/GitRepo/SGP-Chat/notebook/../SGPChat/MicroGridOpt.py:157\u001b[0m, in \u001b[0;36mMicroGridOptAgent.generate_reply\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m reply\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m sender \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_writer:\n\u001b[1;32m    156\u001b[0m     \u001b[39m# reply to writer\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     execution_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_reply_to_writer(sender)\n\u001b[1;32m    158\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExecution out\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    159\u001b[0m     \u001b[39mprint\u001b[39m(execution_out)\n",
            "File \u001b[0;32m~/Documents/GitRepo/SGP-Chat/notebook/../SGPChat/MicroGridOpt.py:170\u001b[0m, in \u001b[0;36mMicroGridOptAgent._generate_reply_to_writer\u001b[0;34m(self, sender)\u001b[0m\n\u001b[1;32m    168\u001b[0m _, code \u001b[39m=\u001b[39m extract_code(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_message(sender)[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m])[\u001b[39m0\u001b[39m]\n\u001b[1;32m    169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcode \u001b[39m=\u001b[39m code\n\u001b[0;32m--> 170\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitiate_chat(message\u001b[39m=\u001b[39;49mSAFEGUARD_PROMPT\u001b[39m.\u001b[39;49mformat(code\u001b[39m=\u001b[39;49mcode),\n\u001b[1;32m    171\u001b[0m                    recipient\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_safeguard)\n\u001b[1;32m    172\u001b[0m safe_msg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_message(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_safeguard)[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m safe_msg\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mDANGER\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    174\u001b[0m     \u001b[39m# Step 4 and 5: Run the code and obtain the results\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:521\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[1;32m    509\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 521\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:324\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    322\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 324\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[1;32m    325\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m     )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:452\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:764\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 764\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    765\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    766\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/agentchat/conversable_agent.py:596\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    593\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m    595\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m--> 596\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    597\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[1;32m    598\u001b[0m )\n\u001b[1;32m    599\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py:770\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[1;32m    768\u001b[0m     base_config[\u001b[39m\"\u001b[39m\u001b[39mretry_timeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    769\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 770\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    771\u001b[0m         context,\n\u001b[1;32m    772\u001b[0m         use_cache,\n\u001b[1;32m    773\u001b[0m         raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mi \u001b[39m<\u001b[39;49m last \u001b[39mor\u001b[39;49;00m raise_on_ratelimit_or_timeout,\n\u001b[1;32m    774\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbase_config,\n\u001b[1;32m    775\u001b[0m     )\n\u001b[1;32m    776\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m    777\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py:801\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mwith\u001b[39;00m diskcache\u001b[39m.\u001b[39mCache(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcache_path) \u001b[39mas\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_cache:\n\u001b[1;32m    800\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset_cache(seed)\n\u001b[0;32m--> 801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_response(params, raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mraise_on_ratelimit_or_timeout)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/flaml/autogen/oai/completion.py:206\u001b[0m, in \u001b[0;36mCompletion._get_response\u001b[0;34m(cls, config, raise_on_ratelimit_or_timeout, use_cache)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrequest_timeout\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config:\n\u001b[0;32m--> 206\u001b[0m         response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n\u001b[1;32m    207\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m         response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39mcreate(request_timeout\u001b[39m=\u001b[39mrequest_timeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         url,\n\u001b[1;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    291\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    298\u001b[0m     )\n\u001b[0;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m         ),\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    777\u001b[0m     )\n\u001b[1;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for gpt-3.5-turbo-1106 in organization org-G8HBZUkjPs0m6dOKNS6nQBs5 on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing."
          ]
        }
      ],
      "source": [
        "with open(file_path, \"r\") as csvfile:\n",
        "        csv_reader = csv.DictReader(csvfile)\n",
        "        counter = 0\n",
        "        for row in csv_reader:\n",
        "            counter += 1\n",
        "            question = row['Question']\n",
        "            if question not in data_dict.keys():\n",
        "                gt_code = row['GT Code']\n",
        "                gt_obj_value = row['GT Objective Value']\n",
        "                user.initiate_chat(agent, message=question)\n",
        "                execution_rst = agent.execution_out\n",
        "                gpt_code = agent.code\n",
        "                #print(execution_rst)\n",
        "                data_dict[question] = {\n",
        "                    'GT Code': gt_code,\n",
        "                    'GT Objective Value': gt_obj_value,\n",
        "                    'SGP Code': gpt_code,\n",
        "                    'SGP Objective Value': execution_rst,\n",
        "                    'SGP Interpretation' : agent.reply\n",
        "                    }\n",
        "                with open(file_path.replace(\".csv\", \"_finalprocessed_gpt3_noicl.csv\"), 'w', newline='') as csvfile:\n",
        "                    fieldnames = ['Question', 'GT Code', 'GT Objective Value', 'SGP Code', 'SGP Objective Value', 'SGP Interpretation']\n",
        "                    csv_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "                    # Writing the header\n",
        "                    csv_writer.writeheader()\n",
        "\n",
        "                    # Writing dictionary entries\n",
        "                    for question, values in data_dict.items():\n",
        "                        csv_writer.writerow({'Question': question, **values})\n",
        "\n",
        "                time.sleep(30)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
